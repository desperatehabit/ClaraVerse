[EPIC 2 - Step 2 - WebRTC Audio Streaming Pipeline]
1. Primary Task:
   - Implement the client-side WebRTC service. This service is responsible for getting microphone access from the user, establishing a peer-to-peer connection with the LiveKit server, and streaming the user's audio in real-time. This is the foundational client-side component of the voice system. (Source: project_planv2.md, Section 4.2)

2. File Locations:
   - To be Created (Inferred frontend service structure):
     - src/features/voice/: A new directory for the voice feature.
     - src/features/voice/services/: A new directory for client-side voice services.
     - src/features/voice/services/ClaraWebRTCService.ts: The main class to manage the WebRTC connection and audio streaming.
     - src/features/voice/services/types.ts: To store client-side specific types like WebRTCConnection and VoiceSession.

3. UI/Component Specification:
   - Not applicable. This is a non-UI, client-side service implementation. It will enable future UI components but has no visual aspect itself.

4. State Management Logic:
   - A new Zustand store will be created to manage the state of the WebRTC connection from the frontend's perspective.
   - src/features/voice/state/voiceStore.ts (Inferred):
     - State:
       - connectionState: 'disconnected' | 'connecting' | 'connected' | 'failed'
       - isMicrophoneEnabled: boolean
       - error: string | null
     - Actions:
       - connect(roomId: string, participantId: string): Promise<void>
       - disconnect(): Promise<void>

5. Data Model & Schema:
   - This step implements the client-side data models detailed in project_planv2.md, Section 4.2, specifically WebRTCConnection and VoiceSession.
     ```typescript
     // src/features/voice/services/types.ts
     export type ConnectionState = 'connecting' | 'connected' | 'disconnected' | 'failed' | 'reconnecting';

     export interface WebRTCConnection {
       peerConnection: RTCPeerConnection;
       audioTrack: MediaStreamTrack | null;
       connectionState: ConnectionState;
     }
     ```

6. Backend Interaction Logic:
   - The ClaraWebRTCService will interact with the LiveKit server for signaling (exchanging connection information).
   - ClaraWebRTCService.ts:
     - initialize(): Request microphone permissions using navigator.mediaDevices.getUserMedia(). If successful, it will create a local MediaStreamTrack.
     - connect(roomId, participantId):
       1. Create an RTCPeerConnection instance using STUN servers for NAT traversal.
       2. Use the livekit-client SDK to connect to the specified roomId.
       3. Once connected to the room, publish the local audio track (MediaStreamTrack) to the room. This action streams the audio to the server.
     - disconnect(): Unpublish the audio track and disconnect from the LiveKit room, which will tear down the RTCPeerConnection.

7. Relevant Documentation & Examples:
   - livekit-client SDK Usage:
     ```typescript
     // In ClaraWebRTCService.ts
     import { Room, RoomEvent, LocalAudioTrack } from 'livekit-client';

     public async connect(roomName: string, participantIdentity: string, token: string) {
       const room = new Room();
       this.room = room; // Store room instance

       room.on(RoomEvent.Connected, () => {
         console.log('✅ Successfully connected to LiveKit room');
         this.publishMicrophoneTrack();
       });

       // The token must be generated by a trusted server-side component
       await room.connect('wss://https://www.google.com/search?q=your-livekit-url.com', token);
     }

     private async publishMicrophoneTrack() {
       const audioTrack = await this.getLocalAudioTrack();
       await this.room.localParticipant.publishTrack(audioTrack);
     }
     ```

8. Error Handling:
   - Microphone Permission Denied: The getUserMedia() call will throw a NotAllowedError if the user denies permission.
     - Logic: The initialize or connect method must catch this error.
     - UI Feedback (via state): The state store's error property should be updated with a message: "Microphone access is required for voice chat. Please enable it in your system settings."
   - Connection Failure: The room.connect() call can fail due to network issues or an invalid token.
     - Logic: The promise will reject. The connect action in the store should catch this.
     - UI Feedback (via state): The connectionState should be set to 'failed', and the error property updated: "Failed to connect to the voice server. Please check your internet connection."

9. Coding Standards & Verification:
   - The ClaraWebRTCService should encapsulate all direct interaction with the livekit-client SDK.
   - The Zustand store should be the single source of truth for connection state for the UI.
   - Verification Checklist:
     - 1. When the connect action is called, the browser prompts for microphone permission.
     - 2. After granting permission, the client successfully connects to the LiveKit server.
     - 3. In the Electron main process console, the onParticipantJoined log from the ClaraVoiceAgent (from Step 1) is visible.
     - 4. Use the LiveKit Room Debugger or server-side logs to confirm that an audio track from the new participant has been successfully published.
     - 5. When the disconnect action is called, the onParticipantLeft log appears in the main process console.
     - 6. If microphone permission is denied, the voiceStore state is correctly updated to show an error.